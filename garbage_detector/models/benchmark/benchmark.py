import numpy as np
from garbage_detector.models import train, validate
from garbage_detector.models.benchmark import DatasetSize
from garbage_detector.models.classification.cnn import CNNModelGenerator
from garbage_detector.models.detection.fasterrcnn import (
    FasterRCNNModel, FasterRCNNModelGenerator)
from garbage_detector.models.detection.fasterrcnn.custom import (
    mobile_net_backbone, resnet50_backbone)
from garbage_detector.models.util import save_states


def run_benchmark(model_list, device, lr, gamma, step_size, out_features, criterion, train_loaders, test_loader, epochs, is_fasterrcnn=False):
    """Runs the benchmark, distinguishing between classification and detection models (CNN vs FasterRCNN)

    For each data size, a new model is generated so that the effect of using different data sets can be accurately evaluated
    For the classification or CNN models, the accuracy/performance of the classification is calculated by the proportion
    of correct predictions to total predictions.
    For the detection or FasterRCNN models, the performance is generated by the library torchmetrics.

    Parameters
    ----------
    model_list: list[str]
        List of model names that are tested in the benchmark.

    device: str
        The name of the device to which the model is attached.

    lr: float
        Learning rate for the optimizer of the model.

    step_size: int
        Step size for the scheduler.

    gamma: float
        Gamma value for the scheduler.

    out_features: int
        The Number of classes that can be classified/detected.

    criterion: Function
        The loss function of the detection model.
        It is not used when running the benchmark on detection models, since internally they use their own
        loss function.

    train_loaders: dict[torch.utils.data.DataLoader]
        The dict containing the data loaders at different dataset sizes.

    test_loader: torch.utils.data.DataLoader
        The data loader, which contains the data to be evaluated against.

    epochs: int
        The number of epochs in which the models are trained before they are validated with the test data.

    is_fasterrcnn: bool
        The flag that indicates whether benchmark is running tests for object classification or detection.
        The default is False, meaning object classification.

    Returns
    -------
    list[dict]
        containing the results for each model with different sizes of datasets.

    """

    results = []
    fasterrcnn_model_gen = FasterRCNNModelGenerator()
    (model, optimizer, scheduler) = (None, None, None)
    for m_name in model_list:
        data_sizes = train_loaders.keys()
        for size in data_sizes:
            if is_fasterrcnn:
                if m_name == FasterRCNNModel.CUSTOM_RESNET_50:
                    (model, optimizer, scheduler) = fasterrcnn_model_gen.create_model_with_custom_backbone(
                        resnet50_backbone, lr, gamma, step_size, out_features)
                elif m_name == FasterRCNNModel.CUSTOM_MOBILE_NET:
                    (model, optimizer, scheduler) = fasterrcnn_model_gen.create_model_with_custom_backbone(
                        mobile_net_backbone, lr, gamma, step_size, out_features)
                else:
                    model, optimizer, scheduler = fasterrcnn_model_gen.create_model(
                        m_name, lr, gamma, step_size, out_features)
            else:
                (model, optimizer, scheduler) = CNNModelGenerator.get_pretrained(
                    m_name, lr, gamma, step_size, out_features)

            for _ in range(0, epochs):
                train(model, device,
                      train_loaders[size], optimizer, loss_criterion=criterion)
                scheduler.step()

            if is_fasterrcnn:
                def trunc(x): return np.trunc(x.item()*1000)/10
                metrics = validate(model, device,  test_loader)
                results.append({'model': m_name, 'dataset': size,
                               'map': trunc(metrics['map']), 'map_50': trunc(metrics['map_50']), 'map_75': trunc(metrics['map_75']), 'mar_100': trunc(metrics['mar_100'])})
            else:
                accuracy = validate(model, device, test_loader)
                results.append(
                    {'model': m_name, 'dataset': size, 'accuracy': accuracy})

            # Only store the training with the largest data set for later use in the jupyter notebook.
            if size == DatasetSize.LARGE:
                save_states(f'{m_name}', model, optimizer)
    return results
